{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heavy-tailed kernels reveal a finer cluster structure in t-SNE visualisations\n",
    "\n",
    "#### Dmitry Kobak, George Linderman, Stefan Steinerberger, Yuval Kluger, Philipp Berens\n",
    "\n",
    "##### http://arxiv.org/abs/1902.05804\n",
    "\n",
    "#### Notebook written by Dmitry Kobak (Jan--Feb 2019; updated in Mar, then Jun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의사항\n",
    "- fitsne 라이브러리의 경우 원래 설치 과정에서 다음과 같은 두 명령어를 실행해야 함.\n",
    "- 따라서 Anaconda Prompt를 실행하여 다음과 같은 두 명령어를 실행한다.\n",
    "    - conda config --add channels conda-forge\n",
    "    - conda install cython numpy fftw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "# 현재 파일의 밖 위치의 파일 리스트를 보여준다.\n",
    "print(os.listdir(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "# 시각화를 위해서 필요한 값들을 미리 정의.\n",
    "def sns_styleset():\n",
    "    sns.set_context('paper')\n",
    "    sns.set_style('ticks')\n",
    "    matplotlib.rcParams['axes.linewidth']    = .75\n",
    "    matplotlib.rcParams['xtick.major.width'] = .75\n",
    "    matplotlib.rcParams['ytick.major.width'] = .75\n",
    "    matplotlib.rcParams['xtick.major.size'] = 3\n",
    "    matplotlib.rcParams['ytick.major.size'] = 3\n",
    "    matplotlib.rcParams['xtick.minor.size'] = 2\n",
    "    matplotlib.rcParams['ytick.minor.size'] = 2\n",
    "    matplotlib.rcParams['font.size']       = 7\n",
    "    matplotlib.rcParams['axes.titlesize']  = 7\n",
    "    matplotlib.rcParams['axes.labelsize']  = 7\n",
    "    matplotlib.rcParams['legend.fontsize'] = 7\n",
    "    matplotlib.rcParams['xtick.labelsize'] = 7\n",
    "    matplotlib.rcParams['ytick.labelsize'] = 7\n",
    "\n",
    "sns_styleset()\n",
    "\n",
    "# Version 1.1.0\n",
    "# 라이브러리를 직접 컴파일하여 설치하기 힘들어서 폴더 채로 받아서,\n",
    "# system 환경 변수에 폴더 위치를 추가한다.\n",
    "import sys; import os;\n",
    "sys.path.append(os.path.expanduser('../FIt-SNE'))\n",
    "\n",
    "# 논문에서 사용한 fast_tsne\n",
    "from fast_tsne import fast_tsne\n",
    "\n",
    "# 나중에 색을 입히기 위한 배열\n",
    "col = np.array(['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99',\n",
    "                '#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a', '#ffff99'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # sample size per class\n",
    "p = 10  # dimensionality\n",
    "k = 10  # number of classes\n",
    "d = 4   # distance between each class mean and 0\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(k*n, p)\n",
    "\n",
    "# sample size의 구간에다가 d를 더하는 과정\n",
    "for i in range(k):\n",
    "    X[i*n:(i+1)*n, i] += d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 형태의 데이터로 fast_tsne에 넣어주면 2차원으로 차원 축소를 자동으로 하므로.\n",
    "### 그저 할 일은 결과 그림을 효과적으로 보기 위해 아래 코드에 익숙해진 후 조금씩 수정하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfs = [100, 1, .5]   # alpha values to use\n",
    "\n",
    "Z_toy1 = []\n",
    "# 실행하는데 원래 시간이 오래 걸립니다. 전산실 컴퓨터로도 한 2분 정도 걸립니다.\n",
    "# 차원 분석에 있어서 원래, t-SNE가 PCA보다 오래 걸리는 단점이 있다.\n",
    "for df in dfs:\n",
    "    # fast_tsne를 실행하는데, df를 달리해서 결과를 Z_toy1에 넣어준다.\n",
    "    # 논문에서 밝힌 의미를 가지는 v가 df에 해당한다.\n",
    "    Z = fast_tsne(X, perplexity=50, seed=42, df=df, theta=0)\n",
    "    Z_toy1.append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림을 그려주는데, 세 가지 종류의 그림을 그리기 위해, ax에 추가해주는 부분.\n",
    "# 아래 코드 모두 어떻게 보면, 여러 그림을 하나의 ax에 넣기 위한 코드.\n",
    "fig = plt.figure(figsize=(4.8, 2))\n",
    "ax = []\n",
    "ax.append(plt.axes([0,   0, .33, .9]))\n",
    "ax.append(plt.axes([.33, 0, .33, .9]))\n",
    "ax.append(plt.axes([.66, 0, .33, .9]))\n",
    "\n",
    "# pyplot에 그림을 넣는 과정\n",
    "for i,Z in enumerate(Z_toy1):\n",
    "    plt.sca(ax[i])\n",
    "    plt.axis('equal', adjustable='box')\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=.2, c=col[np.floor(np.arange(n*k)/n).astype(int)])\n",
    "    plt.title(r'$\\alpha={}$'.format(dfs[i]))\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "\n",
    "# Remove the left and bottom spines from plot(s)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig('figures/fig-toy1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림 아래에 검은색 선과 숫자를 넣어주는 부분\n",
    "hpos = [2, 15, 40] # position\n",
    "hwidth = [1, 10, 10] # width\n",
    "\n",
    "for i in range(3):\n",
    "    plt.sca(ax[i]) # ax 요소 하나를 scatter 해주고,\n",
    "    ax[i].autoscale(False) # 원래 사이즈 그대로 들어가도록 해주고,\n",
    "    yl = plt.ylim() # 축 시작과 끝을 나탸는 배열 반환\n",
    "    vpos      = yl[0] + (yl[1]-yl[0]) * .15\n",
    "    vposlabel = yl[0] + (yl[1]-yl[0]) * .08\n",
    "    plt.plot([hpos[i], hpos[i]+hwidth[i]], [vpos,vpos], 'k', linewidth=1)\n",
    "    plt.text(hpos[i] + hwidth[i]/2, vposlabel, str(hwidth[i]), ha='center')\n",
    "\n",
    "# A, B, C 글자 입력\n",
    "plt.text(0, 1.05, 'A', transform = plt.gcf().get_axes()[0].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'B', transform = plt.gcf().get_axes()[1].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'C', transform = plt.gcf().get_axes()[2].transAxes, fontsize=8, fontweight='bold')\n",
    "    \n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig('figures/fig-toy1.pdf')\n",
    "\n",
    "plt.savefig('figures/png/fig-toy1.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # sample size per class\n",
    "p = 20  # dimensionality\n",
    "k = 10  # number of classes\n",
    "d = 4   # distance between each class mean and 0\n",
    "dw = 4  # distance between each dumbbell sub-clusters\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(k*n, p)\n",
    "for i in range(k):\n",
    "    X[i*n:(i+1)*n, i] += d\n",
    "    X[i*n:i*n+int(n/2), i+k] += dw/2\n",
    "    X[i*n+int(n/2):(i+1)*n, i+k] -= dw/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfs = [100, 1, .5]   # alpha values to use\n",
    "\n",
    "Z_toy2 = []\n",
    "for df in dfs:\n",
    "    Z = fast_tsne(X, perplexity=50, seed=42, df=df, theta=0)\n",
    "    Z_toy2.append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4.8, 2))\n",
    "ax = []\n",
    "ax.append(plt.axes([0,   0, .33, .9]))\n",
    "ax.append(plt.axes([.33, 0, .33, .9]))\n",
    "ax.append(plt.axes([.66, 0, .33, .9]))\n",
    "\n",
    "for i,Z in enumerate(Z_toy2):\n",
    "    plt.sca(ax[i])\n",
    "    plt.axis('equal', adjustable='box')\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=.2, c=col[np.floor(np.arange(n*k)/n).astype(int)])\n",
    "    plt.title(r'$\\alpha={}$'.format(dfs[i]))\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig('figures/fig-toy2.pdf')\n",
    "\n",
    "hpos = [1.5, 13, 40]\n",
    "hwidth = [1, 10, 10]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.sca(ax[i])\n",
    "    ax[i].autoscale(False)\n",
    "    yl = plt.ylim()\n",
    "    vpos      = yl[0] + (yl[1]-yl[0]) * .15\n",
    "    vposlabel = yl[0] + (yl[1]-yl[0]) * .08\n",
    "    plt.plot([hpos[i], hpos[i]+hwidth[i]], [vpos,vpos], 'k', linewidth=1)\n",
    "    plt.text(hpos[i] + hwidth[i]/2, vposlabel, str(hwidth[i]), ha='center')\n",
    "    \n",
    "plt.text(0, 1.05, 'A', transform = plt.gcf().get_axes()[0].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'B', transform = plt.gcf().get_axes()[1].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'C', transform = plt.gcf().get_axes()[2].transAxes, fontsize=8, fontweight='bold')\n",
    "    \n",
    "plt.savefig('figures/fig-toy2.pdf')\n",
    "plt.savefig('figures/png/fig-toy2.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary Figure -- what happens when alpha is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# 말 그대로 df가 굉장히 낮을 때를 실험해본 결과, 학습에 있어서 하나는 5000으로 제한.\n",
    "Z1 = fast_tsne(X, perplexity=50, seed=42, df=.1, theta=0)\n",
    "Z2 = fast_tsne(X, perplexity=50, seed=42, df=.1, theta=0, max_iter=5000)\n",
    "Z_toy2_cont = [Z1,Z2,Z2,Z2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [r'$\\alpha=0.1$'+'\\n1000 iterations (default)', r'$\\alpha=0.1$'+'\\n5000 iterations',\n",
    "          r'$\\alpha=0.1$'+'\\n5000 iterations\\nZoom-in without outliers',\n",
    "          r'$\\alpha=0.1$'+'\\n5000 iterations\\nZoom-in on one \"dumbbell\"']\n",
    "\n",
    "zoomins = [None, None, [-120,120,-120,120], [76.1,76.7,31.35,31.95]]\n",
    "\n",
    "fig = plt.figure(figsize=(4.8, 4.8))\n",
    "for i,Z in enumerate(Z_toy2_cont):\n",
    "    # subplot(nrows, ncols, index)\n",
    "    plt.subplot(2,2,i+1) # 2*2 4개의 그림에서 index에 해당하는 그림판 생성, \n",
    "    plt.axis('equal', adjustable='box')\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=5, c=col[np.floor(np.arange(n*k)/n).astype(int)], alpha=.5, edgecolors='none')\n",
    "    plt.title(titles[i])\n",
    "    if zoomins[i] is not None:\n",
    "        # xmin, xmax, ymin, ymax = axis([xmin, xmax, ymin, ymax])\n",
    "        plt.axis(zoomins[i])\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/suppl-fig-lowalpha.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example 3 (separation as a function of alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def pdist2(A,B):\n",
    "    D = np.sum(A**2,axis=1,keepdims=True) + np.sum(B**2, axis=1, keepdims=True).T - 2*A@B.T\n",
    "    return D\n",
    "\n",
    "# y축에 해당하는 Between/Within distance ratio를 구하기 위한 함수.\n",
    "def stnr(Z,k):\n",
    "    Zmeans =  np.zeros((k, Z.shape[1]))\n",
    "    # Z 배열과 같은 크기의 Zwithin을 생성\n",
    "    Zwithin = np.zeros_like(Z)\n",
    "    n = int(Z.shape[0]/k)\n",
    "\n",
    "    for i in range(k):\n",
    "        Zmeans[i,:] = Z[i*n:(i+1)*n, :].mean(axis=0)\n",
    "        Zwithin[i*n:(i+1)*n, :] = Z[i*n:(i+1)*n, :] - Zmeans[i,:]\n",
    "    \n",
    "    D2between = np.sum(pdist2(Zmeans, Zmeans)) / (Zmeans.shape[0]**2 - Zmeans.shape[0])\n",
    "    D2within  = np.sum(pdist2(Zwithin, Zwithin)) / (Zwithin.shape[0]**2 - Zwithin.shape[0])\n",
    "    return np.sqrt(D2between/D2within)\n",
    "\n",
    "\n",
    "n = 100 # sample size per class\n",
    "p = 10  # dimensionality\n",
    "k = 2   # number of classes\n",
    "d = 5   # distance between each class mean and 0\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(k*n, p)\n",
    "for i in range(k):\n",
    "    X[i*n:(i+1)*n, i] += d\n",
    "    \n",
    "dfs = np.arange(.2, 3.1, .1)\n",
    "# dfs 배열과 같은 stnrs를 생성\n",
    "stnrs = np.zeros_like(dfs)\n",
    "for i,df in enumerate(dfs):\n",
    "    print('.', end='')\n",
    "    Z = fast_tsne(X, perplexity=50, seed=42, df=df, theta=0)\n",
    "    stnrs[i] = stnr(Z,k)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 2))\n",
    "plt.plot(dfs,  stnrs,  'ko-', linewidth=1, markersize=2, zorder=1)\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('Between/within distance ratio')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.savefig('figures/fig-separation.pdf')\n",
    "plt.savefig('figures/png/fig-separation.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 라이브러리를 설치하는 명령어. 보통의 경우 anaconda prompt에서 설치하는 것이 좋음.\n",
    "# Keras is a high-level neural networks API.\n",
    "# 따라서 라이브러리 내에 다양한 데이터 셋을 가지고 있다. scikit learn도 다양한 데이터를 내장하고 있듯이.\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "\n",
    "# 데이터가 총 7만개인데, load_data할 때 자동으로 쪼개져서 반환할 수 있다.\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 이미지 데이터 벡터이기 때문에, 28*28의 2차원을 784인 1차원으로 다시 만들어 줌. \n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float64')\n",
    "x_test = x_test.astype('float64')\n",
    "x_train /= 255 # 색깔 픽셀이기 때문에 이런 처리.\n",
    "x_test /= 255\n",
    "X = np.concatenate((x_train, x_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "print(X.shape)\n",
    "\n",
    "# 주어진 벡터를 Singular Value Decomposition 통해 쪼개는 방법.\n",
    "U, s, V = np.linalg.svd(X - X.mean(axis=0), full_matrices=False)\n",
    "X50 = np.dot(U, np.diag(s))[:,:50]\n",
    "PCAinit = X50[:,:2] / np.std(X50[:,0]) * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_mnist = []\n",
    "%time Z = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, df=100)\n",
    "Z_mnist.append(Z)\n",
    "%time Z = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, df=1)\n",
    "Z_mnist.append(Z)\n",
    "%time Z = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, df=.5)\n",
    "Z_mnist.append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [100, 1, .5]\n",
    "fig = plt.figure(figsize=(4.8, 1.5))\n",
    "w = .28\n",
    "ax = []\n",
    "ax.append(plt.axes([0,0,w,.88]))\n",
    "ax.append(plt.axes([w,0,w,.88]))\n",
    "ax.append(plt.axes([2*w,0,w,.88]))\n",
    "\n",
    "for i,Z in enumerate(Z_mnist):\n",
    "    plt.sca(ax[i])\n",
    "    plt.axis('equal', adjustable='box')\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=.5, c=col[y], rasterized=True, alpha=.5, edgecolors='none')\n",
    "    plt.title(r'$\\alpha={}$'.format(dfs[i]))\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    \n",
    "    # 첫번째 그래프에 각 class의 번호를 그려주는 부분\n",
    "    if i==0:\n",
    "        for digit in range(10):\n",
    "            plt.text(np.mean(Z[y==digit,0]), np.mean(Z[y==digit,1]), digit, ha='center', va='center')\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig('figures/fig-mnist.pdf')\n",
    "\n",
    "hpos = [7, 40, 30]\n",
    "hwidth = [1, 10, 10]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.sca(ax[i])\n",
    "    ax[i].autoscale(False)\n",
    "    yl = plt.ylim()\n",
    "    vpos      = yl[0] + (yl[1]-yl[0]) * .15\n",
    "    vposlabel = yl[0] + (yl[1]-yl[0]) * .08\n",
    "    plt.plot([hpos[i], hpos[i]+hwidth[i]], [vpos,vpos], 'k', linewidth=1)\n",
    "    plt.text(hpos[i] + hwidth[i]/2, vposlabel, str(hwidth[i]), ha='center')\n",
    "    \n",
    "plt.text(0, 1.05, 'A', transform = plt.gcf().get_axes()[0].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'B', transform = plt.gcf().get_axes()[1].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'C', transform = plt.gcf().get_axes()[2].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(.95, 1.05, 'D', transform = plt.gcf().get_axes()[2].transAxes, fontsize=8, fontweight='bold')\n",
    "    \n",
    "plt.savefig('figures/fig-mnist.pdf', dpi=600)\n",
    "\n",
    "\n",
    "# Perform DBSCAN clustering from vector array or distance matrix.\n",
    "\n",
    "# DBSCAN - Density-Based Spatial Clustering of Applications with Noise. \n",
    "#          Finds core samples of high density and expands clusters from them. \n",
    "#          Good for data which contains clusters of similar density.\n",
    "from sklearn.cluster import DBSCAN\n",
    "# 마지막에 해당하는 Z에 대해서\n",
    "Z = Z_mnist[-1]\n",
    "# 표시하고자 하는 class의 index (숫자 1, 2, 4)\n",
    "digits = [1, 4, 2]\n",
    "arrowdx = [[10,10], [0, 10*np.sqrt(2)], [10, 10]]\n",
    "for digitnum, digit in enumerate(digits):\n",
    "    # 해당 클래스에 대하여 클러스터링 하고,\n",
    "    clustering = DBSCAN().fit(Z[y==digit,:])\n",
    "    # 클러스터들의 label과 각 라벨에 해당하는 데이터 수인 count\n",
    "    labels, counts = np.unique(clustering.labels_, return_counts=True)\n",
    "    counts = counts[labels>=0]\n",
    "    labels = labels[labels>=0]\n",
    "    # 가장 많은 숫자대로 정렬\n",
    "    order = np.argsort(counts)[::-1]\n",
    "    counts = counts[order]\n",
    "    labels = labels[order]\n",
    "    \n",
    "    # 카운트가 100이상에 해당하는 친구들만 화살표를 그려주기로 함.\n",
    "    for i in np.where(counts>100)[0][:5]:\n",
    "        plt.axes([.85 + .045*digitnum, .7 - .15*i, .12*2.3/7, .12])\n",
    "        ind = clustering.labels_ == labels[i]\n",
    "        # 각 클러스터의 중앙에 있는 데이터를 보여준다.\n",
    "        plt.imshow(np.mean(X[y==digit,:][ind,:],axis=0).reshape(28,28), \n",
    "                   interpolation=\"nearest\", vmin=0, vmax=1)\n",
    "        plt.gray()\n",
    "        plt.axis('off')\n",
    "        plt.sca(ax[2])\n",
    "        mu = np.mean(Z_mnist[2][y==digit,:][ind,:], axis=0)\n",
    "        if mu[1]<25 and digit==4:\n",
    "            dx = np.array([10, 10])\n",
    "        else:\n",
    "            dx = np.array(arrowdx[digitnum])\n",
    "        # D에 그려준 데이터에 해당하는 클러스터에 화살표 표시를 한다.\n",
    "        plt.annotate('', xy=mu+dx/10, xytext=mu+dx, \n",
    "                     arrowprops=dict(arrowstyle='->', color='k', linewidth=.6))\n",
    "\n",
    "plt.savefig('figures/fig-mnist.pdf', dpi=600)\n",
    "plt.savefig('figures/png/fig-mnist.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP comparison for MNIST  (Supplementary Figures)\n",
    "Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction. The algorithm is founded on three assumptions about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install umap, implement below command in anaconda prompt\n",
    "# !conda install -c conda-forge umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "print('UMAP version: ' + umap.__version__)\n",
    "\n",
    "# UMAP code for computing $a$ and $b$ given min_dist\n",
    "# Copied verbatim from the UMAP source code\n",
    "from scipy.optimize import curve_fit\n",
    "def find_ab_params(spread, min_dist):\n",
    "    \"\"\"Fit a, b params for the differentiable curve used in lower\n",
    "    dimensional fuzzy simplicial complex construction. We want the\n",
    "    smooth curve (from a pre-defined family with simple gradient) that\n",
    "    best matches an offset exponential decay.\n",
    "    \"\"\"\n",
    "\n",
    "    def curve(x, a, b):\n",
    "        return 1.0 / (1.0 + a * x ** (2 * b))\n",
    "\n",
    "    xv = np.linspace(0, spread * 3, 300)\n",
    "    yv = np.zeros(xv.shape)\n",
    "    yv[xv < min_dist] = 1.0\n",
    "    yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)\n",
    "    params, covar = curve_fit(curve, xv, yv)\n",
    "    return params[0], params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# min_dist: This controls how tightly the embedding is allowed compress points together. \n",
    "# Larger values ensure embedded points are more evenly distributed, while smaller values allow \n",
    "# the algorithm to optimise more accurately with regard to local structure. Sensible values \n",
    "# are in the range 0.001 to 0.5, with 0.1 being a reasonable default.\n",
    "\n",
    "dists = [.5, .1, .01, np.nan]\n",
    "\n",
    "Zumap = []\n",
    "umap_b = []\n",
    "umap_a = []\n",
    "for d in dists:\n",
    "    print('.', flush=True, end='')\n",
    "    if ~np.isnan(d):\n",
    "        Z = umap.UMAP(min_dist=d).fit_transform(X50)\n",
    "        umap_a.append(find_ab_params(1,d)[0])    \n",
    "        umap_b.append(find_ab_params(1,d)[1])    \n",
    "    else:\n",
    "        Z = umap.UMAP(a=1, b=0.3).fit_transform(X50)\n",
    "        umap_a.append(1)    \n",
    "        umap_b.append(0.3)    \n",
    "    Zumap.append(Z)    \n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zumap[0][:,0] = -Zumap[0][:,0]\n",
    "Zumap[2][:,0] = -Zumap[2][:,0]\n",
    "\n",
    "fig = plt.figure(figsize=(4.8, 4.8))\n",
    "for i,Z in enumerate(Zumap):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=1, c=col[y], rasterized=True, alpha=.5, edgecolors='none')\n",
    "    if ~np.isnan(dists[i]):\n",
    "        plt.title('min_dist={}\\na={:.2f}, b={:.2f}'.format(dists[i], umap_a[i], umap_b[i]))\n",
    "    else:\n",
    "        plt.title('\\na={:.2f}, b={:.2f}'.format(umap_a[i], umap_b[i]))            \n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figures/suppl-fig-umap.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longer optimisation, lower alpha, and isolated digits (Supplementary Figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Z10k = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, df=.5, max_iter=10000)\n",
    "pickle.dump(Z10k, open('pickles/Zmnist10k.pickle', 'wb'))\n",
    "\n",
    "# final loss: 3.615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z10k = pickle.load(open('pickles/Zmnist10k.pickle', 'rb'))\n",
    "%time Z = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, df=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.8,4.8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.axis('equal', adjustable='box')\n",
    "plt.scatter(Z[:,0], Z[:,1], s=1, c=col[y], rasterized=True, alpha=.5, edgecolors='none')\n",
    "plt.title(r'$\\alpha=0.5$'+'\\n1000 iterations')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.axis('equal', adjustable='box')\n",
    "plt.scatter(Z10k[:,0], Z10k[:,1], s=1, c=col[y], rasterized=True, alpha=.5, edgecolors='none')\n",
    "plt.title(r'$\\alpha=0.5$'+'\\n10000 iterations')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.axis('equal', adjustable='box')\n",
    "ind = (y==4) & (Z[:,0]>-5) & (Z[:,0]<20) & (Z[:,1]>15) & (Z[:,0]<45)\n",
    "plt.scatter(Z[ind,0], Z[ind,1], s=1, c=col[4], rasterized=True, alpha=.5, edgecolors='none')\n",
    "plt.title(r'$\\alpha=0.5$'+'\\n1000 iterations\\nZoom-in on digit 4')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.axis('equal', adjustable='box')\n",
    "ind = (y==4) & (Z10k[:,0]>-10) & (Z10k[:,0]<50) & (Z10k[:,1]>80) & (Z10k[:,0]<200)\n",
    "plt.scatter(Z10k[ind,0], Z10k[ind,1], s=1, c=col[4], rasterized=True, alpha=.5, edgecolors='none')\n",
    "plt.title(r'$\\alpha=0.5$'+'\\n10000 iterations\\nZoom-in on digit 4')\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/suppl-fig-mnist10k.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Isolated digit of MNIST\n",
    "\n",
    "print('Number of images of digit 4: {}'.format(np.sum(y==4)))\n",
    "\n",
    "Zisolated = []\n",
    "Z = fast_tsne(X50[y==4], perplexity=50, df=.5, max_iter=1000, initialization=PCAinit[y==4,:])\n",
    "Zisolated.append(Z)\n",
    "\n",
    "Xext = [X50[y==4]]\n",
    "for i in range(3):\n",
    "    Z = np.random.randn(7000, 50)\n",
    "    Z[:,i] += 10\n",
    "    Xext.append(Z)\n",
    "Xext = np.concatenate(Xext)\n",
    "Z = fast_tsne(Xext, perplexity=50, df=.5, seed=42)\n",
    "Zisolated.append(Z)\n",
    "\n",
    "Z = fast_tsne(X50[y==4], perplexity=50, df=.5, max_iter=1000, late_exag_coeff=1.75, start_late_exag_iter=250,\n",
    "             initialization=PCAinit[y==4,:])\n",
    "Zisolated.append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.8, 2))\n",
    "titles = [r'$\\alpha=0.5$', r'$\\alpha=0.5$'+' with extra\\nGaussian clusters', r'$\\alpha=0.5$, exag. 1.75']\n",
    "for i,Z in enumerate(Zisolated):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.axis('equal', adjustable='box')\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=.2, rasterized=True)\n",
    "    plt.title(titles[i])\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/suppl-fig-mnist-isolated.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST scan of the alpha range (animations etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# This takes a lot of time because it prepares three different animations:\n",
    "# 1. Each alpha is initialized with PCA and optimized with default parameters\n",
    "# 2. Each alpha is initialized with the previous one scaled to std=0.0001 and \n",
    "#    optimized without early exaggeration\n",
    "# 3. Each alpha is initialized with the previous one without scaling and\n",
    "#    optimized without exaggeration for 500 iterations. This one is the slowest\n",
    "#    because the size of the embedding keeps growing and FIt-SNE slows down.\n",
    "\n",
    "_ = fast_tsne(X50, perplexity=50, max_iter=100, load_affinities='save')\n",
    "dfs = np.concatenate((np.arange(100,5,-1), np.arange(5,1,-.25), np.arange(1,.499,-.01)))\n",
    "\n",
    "Zmovie1 = []   # each alpha initialized with PCA\n",
    "kls1 = []\n",
    "Zmovie2  = []  # each alpha initialized with the scaled previous one (no exaggeration)\n",
    "kls2  = []\n",
    "Zmovie3 = []   # each alpha initialized with the previous one (500 iter, no exaggeration)\n",
    "kls3 = []\n",
    "for i,df in enumerate(dfs):\n",
    "    print('.', end='')\n",
    "        \n",
    "    Z,kl = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, \n",
    "                     load_affinities='load', df=df, return_loss=True)\n",
    "    Zmovie1.append(Z)\n",
    "    kls1.append(kl[-1])\n",
    "    \n",
    "    if i>0:\n",
    "        Z,kl = fast_tsne(X50, perplexity=50, learning_rate=1000, \n",
    "                         initialization=Zmovie2[-1]/np.std(Zmovie2[-1][:,0])*0.0001, \n",
    "                         load_affinities='load', df=df, return_loss=True, early_exag_coeff=1)\n",
    "    else:\n",
    "        Z1 = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, \n",
    "                       load_affinities='load', df=100)\n",
    "        Z,kl = fast_tsne(X50, perplexity=50, learning_rate=1000, \n",
    "                         initialization=Z1/np.std(Z1[:,0])*0.0001, \n",
    "                         load_affinities='load', df=df, return_loss=True, early_exag_coeff=1)\n",
    "    Zmovie2.append(Z)\n",
    "    kls2.append(kl[-1])\n",
    "    \n",
    "    if i>0:\n",
    "        Z,kl = fast_tsne(X50, perplexity=50, learning_rate=1000, max_iter=500,\n",
    "                         initialization=Zmovie3[-1], \n",
    "                         load_affinities='load', df=df, return_loss=True, early_exag_coeff=1)\n",
    "    else:\n",
    "        Z,kl = fast_tsne(X50, perplexity=50, learning_rate=1000, initialization=PCAinit, \n",
    "                         load_affinities='load', df=100, return_loss=True)\n",
    "    Zmovie3.append(Z)\n",
    "    kls3.append(kl[-1])\n",
    "    \n",
    "    pickle.dump([Zmovie1, Zmovie2, Zmovie3, kls1, kls2, kls3, dfs], open('pickles/Zmovie.pickle', 'wb'))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zmovie1, Zmovie2, Zmovie3, kls1, kls2, kls3, dfs = pickle.load(open('pickles/Zmovie.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zmovie = Zmovie1\n",
    "\n",
    "sns.set()\n",
    "sns.set_style('white')\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ll = plt.text(0, .9, r'$\\alpha={}$'.format(100), transform = plt.gca().transAxes)\n",
    "sc = plt.scatter(Zmovie[0][:,0], Zmovie[0][:,1], c=col[y], s=1, alpha=.5)\n",
    "tt = []\n",
    "for digit in range(10):\n",
    "    t = plt.text(np.mean(Zmovie[0][y==digit,0]), np.mean(Zmovie[0][y==digit,1]), digit, ha='center', va='center')\n",
    "    tt.append(t)\n",
    "sns.despine(left=True, bottom=True)\n",
    "m = np.max(np.abs(Zmovie[0]))\n",
    "plt.xlim([-m, m])\n",
    "plt.ylim([-m, m])\n",
    "plt.gca().get_xaxis().set_visible(False)\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "pauses = [100, 1, 0.5]\n",
    "pauselength = 10\n",
    "frames = []\n",
    "for i,df in enumerate(dfs):\n",
    "    if np.round(df,3) in pauses:\n",
    "        frames += [i]*pauselength\n",
    "    else:\n",
    "        frames += [i]\n",
    "\n",
    "def update_plot(i):\n",
    "    sc.set_offsets(Zmovie[frames[i]])\n",
    "    m = np.max(np.abs(Zmovie[frames[i]]))\n",
    "    plt.xlim([-m, m])\n",
    "    plt.ylim([-m, m])\n",
    "    for digit,t in enumerate(tt):\n",
    "        t.set_position((np.mean(Zmovie[frames[i]][y==digit,0]), \n",
    "                        np.mean(Zmovie[frames[i]][y==digit,1])))\n",
    "    if dfs[frames[i]]>=5:\n",
    "        ll.set_text(r'$\\alpha={}$'.format(int(dfs[frames[i]])))\n",
    "    elif dfs[frames[i]]>=1:\n",
    "        ll.set_text(r'$\\alpha={:.1f}$'.format(dfs[frames[i]]))\n",
    "    else:\n",
    "        ll.set_text(r'$\\alpha={:.2f}$'.format(dfs[frames[i]]))\n",
    "\n",
    "from matplotlib import animation\n",
    "myanim = animation.FuncAnimation(fig, update_plot, frames=len(frames), \n",
    "                                 interval=100, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myanim.save('animations/mnist.gif', dpi=150, writer='imagemagick')\n",
    "\n",
    "# to compress gif (https://github.com/kornelski/giflossy)\n",
    "# /usr/local/bin/gifsicle --lossy=200 --colors 64 -i mnist.gif -o mnist-sm.gif\n",
    "\n",
    "# to convert to mp4\n",
    "# ffmpeg -f gif -i mnist.gif mnist.mp4\n",
    "\n",
    "# direct export to mp4 does not work very well for some reason\n",
    "# myanim.save('animations/test.mp4', dpi=150, writer=animation.writers['ffmpeg'](fps=10))\n",
    "\n",
    "# undo seaborn style set for animation\n",
    "sns_styleset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def mnn(X, Zs, knn=10):\n",
    "    nbrs1 = NearestNeighbors(n_neighbors=knn).fit(X)\n",
    "    ind1 = nbrs1.kneighbors(return_distance=False)\n",
    "        \n",
    "    mnn = np.zeros(len(Zs))\n",
    "    for num, Z in enumerate(Zs):\n",
    "        print('.', end='')\n",
    "        nbrs2 = NearestNeighbors(n_neighbors=knn).fit(Z)\n",
    "        ind2 = nbrs2.kneighbors(return_distance=False)\n",
    "    \n",
    "        intersections = 0.0\n",
    "        for i in range(X.shape[0]):\n",
    "            intersections += len(set(ind1[i]) & set(ind2[i]))\n",
    "        mnn[num] = intersections / X.shape[0] / knn\n",
    "    print('')\n",
    "    \n",
    "    return mnn\n",
    "\n",
    "%time mnns10  = mnn(X50, Zmovie1, knn=10)\n",
    "%time mnns50  = mnn(X50, Zmovie1, knn=50)\n",
    "%time mnns100 = mnn(X50, Zmovie1, knn=100)\n",
    "\n",
    "pickle.dump([mnns10, mnns50, mnns100], open('pickles/mnns-exact.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zmovie1, Zmovie2, Zmovie3, kls1, kls2, kls3, dfs = pickle.load(open('pickles/Zmovie.pickle', 'rb'))\n",
    "[mnns10, mnns50, mnns100] = pickle.load(open('pickles/mnns-exact.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5, 2.2))\n",
    "plt.plot(dfs,  kls1,  'k-', linewidth=1, markersize=1)\n",
    "ax1 = plt.gca()\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('KL divergence')\n",
    "plt.text(60, 3.75, 'KL', color='k')\n",
    "plt.plot(1.5, np.min(kls1), 'ko', markersize=3)\n",
    "\n",
    "yl = plt.ylim()\n",
    "plt.plot([1,1], yl, 'k--', linewidth=0.75, zorder=0)\n",
    "plt.ylim(yl)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "plt.plot(dfs,  mnns10, 'b-', linewidth=1, markersize=1)\n",
    "plt.plot(dfs,  mnns50, 'b-', linewidth=1, markersize=1)\n",
    "plt.plot(dfs,  mnns100, 'b-', linewidth=1, markersize=1)\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "plt.ylabel('KNN preservation', color='b')\n",
    "ax2.plot(dfs[np.argmax(mnns10)], np.max(mnns10), 'bo', markersize=3)\n",
    "ax2.plot(dfs[np.argmax(mnns50)],  np.max(mnns50), 'bo', markersize=3)\n",
    "ax2.plot(dfs[np.argmax(mnns100)],  np.max(mnns100), 'bo', markersize=3)\n",
    "\n",
    "plt.text(50, 0.06, 'K=10', color='b')\n",
    "plt.text(50, 0.13, 'K=50', color='b')\n",
    "plt.text(50, 0.18,  'K=100', color='b')\n",
    "\n",
    "plt.xscale('log')\n",
    "sns.despine(ax=ax1)\n",
    "sns.despine(ax=ax2, right=False, bottom=True)\n",
    "ax2.spines['left'].set_color('none')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/fig-kl.pdf')\n",
    "plt.savefig('figures/png/fig-kl.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasic et al.\n",
    "\n",
    "Download the data from here: http://celltypes.brain-map.org/rnaseq and unpack. Direct links:\n",
    " * VISp: http://celltypes.brain-map.org/api/v2/well_known_file_download/694413985\n",
    " * ALM: http://celltypes.brain-map.org/api/v2/well_known_file_download/694413179\n",
    "\n",
    "To get the information about cluster colors and labels (`sample_heatmap_plot_data.csv`), open the interactive data browser http://celltypes.brain-map.org/rnaseq/mouse, go to \"Sample Heatmaps\", click \"Build Plot!\" and then \"Download data as CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Load the Allen institute data. This takes a bit of time but saves the result \n",
    "# # to a .pickle file that can be quickly loaded afterwards\n",
    "\n",
    "# # This function is needed because using Pandas to load these files in one go \n",
    "# # can eat up a lot of RAM. So we are doing it in chunks, and converting each\n",
    "# # chunk to the sparse matrix format on the fly.\n",
    "# def sparseload(filename):\n",
    "#     with open(filename) as file:\n",
    "#         genes = []\n",
    "#         sparseblocks = []\n",
    "#         for i,chunk in enumerate(pd.read_csv(filename, chunksize=1000, index_col=0)):\n",
    "#             print('.', end='', flush=True)\n",
    "#             if i==0:\n",
    "#                 cells = np.array(chunk.columns)\n",
    "#             genes.extend(list(chunk.index))\n",
    "#             sparseblock = sparse.csr_matrix(chunk.values.astype(float))\n",
    "#             sparseblocks.append([sparseblock])\n",
    "#         counts = sparse.bmat(sparseblocks)\n",
    "#         print(' done')\n",
    "#     return (counts.T, np.array(genes), cells)\n",
    "\n",
    "# filename = '../data/tasic-nature/mouse_VISp_2018-06-14_exon-matrix.csv'\n",
    "# counts1, genes, cells1 = sparseload(filename)\n",
    "\n",
    "# filename = '../data/tasic-nature/mouse_ALM_2018-06-14_exon-matrix.csv'\n",
    "# counts2, genes2, cells2 = sparseload(filename)\n",
    "\n",
    "# counts = sparse.vstack((counts1, counts2), format='csc')\n",
    "# counts1, counts2 = [], []\n",
    "# cells = np.concatenate((cells1, cells2))\n",
    "# assert(np.all(genes==genes2))\n",
    "\n",
    "# genesDF = pd.read_csv('../data/tasic-nature/mouse_VISp_2018-06-14_genes-rows.csv')\n",
    "# ids     = genesDF['gene_entrez_id'].tolist()\n",
    "# symbols = genesDF['gene_symbol'].tolist()\n",
    "# id2symbol = dict(zip(ids, symbols))\n",
    "# genes = np.array([id2symbol[g] for g in genes])\n",
    "\n",
    "# clusterInfo = pd.read_csv('../data/tasic-nature/sample_heatmap_plot_data.csv')\n",
    "# goodCells  = clusterInfo['sample_name'].values\n",
    "# ids        = clusterInfo['cluster_id'].values\n",
    "# labels     = clusterInfo['cluster_label'].values\n",
    "# colors     = clusterInfo['cluster_color'].values\n",
    "\n",
    "# clusterNames  = np.array([labels[ids==i+1][0] for i in range(np.max(ids))])\n",
    "# clusterColors = np.array([colors[ids==i+1][0] for i in range(np.max(ids))])\n",
    "# clusters   = np.copy(ids) - 1\n",
    "\n",
    "# ind = np.array([np.where(cells==c)[0][0] for c in goodCells])\n",
    "# counts = counts[ind, :]\n",
    "\n",
    "# areas = (ind < cells1.size).astype(int)\n",
    "\n",
    "# tasic2018 = {'counts': counts, 'genes': genes, 'clusters': clusters, 'areas': areas, \n",
    "#              'clusterColors': clusterColors, 'clusterNames': clusterNames}\n",
    "\n",
    "# pickle.dump(tasic2018, open('tasic2018.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# The pre-processing follows Kobak & Berens (2018) preprint\n",
    "# https://github.com/berenslab/rna-seq-tsne/ \n",
    "import rnaseqTools\n",
    "\n",
    "tasic2018 = pickle.load(open('tasic2018.pickle', 'rb'))\n",
    "\n",
    "importantGenesTasic2018 = rnaseqTools.geneSelection(tasic2018['counts'], n=3000, threshold=32, \n",
    "                                                    decay=1.5, plot=False)\n",
    "librarySizes = np.sum(tasic2018['counts'], axis=1)\n",
    "X = np.log2(tasic2018['counts'][:, importantGenesTasic2018] / librarySizes * 1e+6 + 1)  \n",
    "X = np.array(X)\n",
    "X = X - X.mean(axis=0)\n",
    "U,s,V = np.linalg.svd(X, full_matrices=False)\n",
    "U[:,np.sum(V,axis=1)<0] *= -1\n",
    "X = np.dot(U, np.diag(s))\n",
    "X = X[:, np.argsort(s)[::-1]][:,:50]\n",
    "\n",
    "PCAinit = X[:,:2]/np.std(X[:,0])*.0001\n",
    "\n",
    "Z_tasic = []\n",
    "Z = fast_tsne(X, perplexity = 50, initialization = PCAinit, df=1)\n",
    "Z_tasic.append(Z)\n",
    "Z = fast_tsne(X, perplexity = 50, initialization = PCAinit, df=.6)\n",
    "Z_tasic.append(Z)\n",
    "Z_tasic.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind = np.array([c.split()[0]=='Vip' for c in tasic2018['clusterNames'][tasic2018['clusters']]])\n",
    "Z_tasic[2] = Z_tasic[1].copy()\n",
    "Z_tasic[2][~ind,:] = np.nan\n",
    "\n",
    "dfs = [1, .6, .6]\n",
    "fig = plt.figure(figsize=(4.8, 2))\n",
    "w = .33\n",
    "ax = []\n",
    "ax.append(plt.axes([0,0,w,.9]))\n",
    "ax.append(plt.axes([w,0,w,.9]))\n",
    "ax.append(plt.axes([2*w,0,w,.9]))\n",
    "\n",
    "for i,Z in enumerate(Z_tasic):\n",
    "    plt.sca(ax[i])\n",
    "    plt.axis('equal', adjustable='box')\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=.2, c=tasic2018['clusterColors'][tasic2018['clusters']],\n",
    "                rasterized=True)#, alpha=.75, edgecolors='none')\n",
    "    plt.title(r'$\\alpha={}$'.format(dfs[i]))\n",
    "    if i==2:\n",
    "        plt.title(r'$\\alpha=0.6$, Vip clusters')\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    \n",
    "# Plot means in subplot 3\n",
    "plt.sca(ax[2])\n",
    "Z = Z_tasic[2]\n",
    "K = tasic2018['clusterNames'].size\n",
    "Zmeans = np.zeros((K, 2)) * np.nan\n",
    "for c in range(K):\n",
    "    if not all(np.isnan(Z[tasic2018['clusters']==c, 0])):\n",
    "        Zmeans[c,:] = np.median(Z[tasic2018['clusters']==c, :2], axis=0)\n",
    "nonans = ~np.isnan(Zmeans[:,0])\n",
    "plt.scatter(Zmeans[nonans,0], Zmeans[nonans,1],\n",
    "            color=tasic2018['clusterColors'][nonans], \n",
    "            s=20, edgecolor='k', linewidth=.5);\n",
    "    \n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig('figures/fig-tasic.pdf', dpi=600)\n",
    "\n",
    "hpos = [25, 20, -10]\n",
    "hwidth = [10, 10, 1]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.sca(ax[i])\n",
    "    ax[i].autoscale(False)\n",
    "    yl = plt.ylim()\n",
    "    vpos      = yl[0] + (yl[1]-yl[0]) * .15\n",
    "    vposlabel = yl[0] + (yl[1]-yl[0]) * .08\n",
    "    plt.plot([hpos[i], hpos[i]+hwidth[i]], [vpos,vpos], 'k', linewidth=1)\n",
    "    plt.text(hpos[i] + hwidth[i]/2, vposlabel, str(hwidth[i]), ha='center')\n",
    "    \n",
    "plt.text(0, 1.05, 'A', transform = plt.gcf().get_axes()[0].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'B', transform = plt.gcf().get_axes()[1].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'C', transform = plt.gcf().get_axes()[2].transAxes, fontsize=8, fontweight='bold')\n",
    "    \n",
    "plt.savefig('figures/fig-tasic.pdf', dpi=600)\n",
    "plt.savefig('figures/png/fig-tasic.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasic2018 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HathiTrust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Data files are from https://zenodo.org/record/1477018\n",
    "meta = pd.read_csv(os.path.expanduser('~/hathi/data_shuffled.tsv'), sep='\\t', error_bad_lines=False)\n",
    "idsRus = np.array(meta['id'])[np.array(meta['language'])=='Russian']\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('/home/localadmin/hathi/hathi_pca.bin', binary=True)\n",
    "\n",
    "X = np.zeros((idsRus.size, 100))\n",
    "for i,ident in enumerate(idsRus):\n",
    "    X[i,:] = model[ident]\n",
    "    \n",
    "print(X.shape)\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting publication dates\n",
    "dates = np.array(meta['date'])[np.array(meta['language'])=='Russian']\n",
    "datesnum = np.zeros(dates.size)\n",
    "datesnum[dates=='None'] = np.nan\n",
    "datesnum[dates!='None'] = dates[dates!='None'].astype(int)\n",
    "datesnum[[d>2018 if ~np.isnan(d) else False for d in datesnum]] = np.nan\n",
    "datesnum[[d<1700 if ~np.isnan(d) else False for d in datesnum]] = np.nan\n",
    "\n",
    "# Most frequent LoC categories\n",
    "lcs = np.array(meta['lc1'])[np.array(meta['language'])=='Russian'].astype('str')\n",
    "types, counts = np.unique(lcs, return_counts=True)\n",
    "print('LIBRARY OF CONGRESS CATEGORIES')\n",
    "for t,c in zip(types [np.argsort(counts)[::-1]][:10], \n",
    "               counts[np.argsort(counts)[::-1]][:10]):\n",
    "    print(t + '\\t {}'.format(c))\n",
    "print('...\\n')\n",
    "\n",
    "# Selecting some poetry\n",
    "authors = np.array(meta['first_author_name'])[np.array(meta['language'])=='Russian'].astype('str')\n",
    "poets = [i for i,s in enumerate(authors) if 'Fet, A. A.' in s \n",
    "         or 'tchev, F. I.' in s or 'Mayakovsky, Vladimir' in s\n",
    "         or 'Akhmatova, Anna' in s or 'Pushkin, Aleksandr' in s\n",
    "         or 'Blok, Aleksandr' in s or 'Mandelʹshtam, Osip' in s\n",
    "         or 'Brodsky, Joseph' in s]\n",
    "\n",
    "print('Poetry books selected: {}'.format(len(poets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Z_hathi = []\n",
    "Z = fast_tsne(X, perplexity=50, learning_rate=10000, seed=42, load_affinities='save')\n",
    "Z_hathi.append(Z)\n",
    "Z = fast_tsne(X, perplexity=50, learning_rate=10000, seed=42, df=.5, load_affinities='load')\n",
    "Z_hathi.append(Z)\n",
    "\n",
    "pickle.dump([Z_hathi, datesnum, lcs, poets], open('pickles/hathi.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Z_hathi, datesnum, lcs, poets] = pickle.load(open('pickles/hathi.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4.8, 2.5))\n",
    "ax = []\n",
    "ax.append(plt.axes([0, 0, .45, .9]))\n",
    "ax.append(plt.axes([.55, 0, .45,.9]))\n",
    "cax   = plt.axes([.46,.18,.02,.5])\n",
    "\n",
    "dfs = [1, .5]\n",
    "for i,Z in enumerate(Z_hathi):\n",
    "    plt.sca(ax[i])\n",
    "    plt.axis('equal', adjustable='box')\n",
    "    plt.scatter(Z[:,0], Z[:,1], s=1, alpha=.5, c=datesnum, rasterized=True, edgecolors='none', cmap='inferno')\n",
    "    plt.title(r'$\\alpha={}$'.format(dfs[i]))\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    \n",
    "# contours\n",
    "Z = Z_hathi[0]\n",
    "plt.sca(ax[0])\n",
    "sns.kdeplot(Z[lcs=='QA',0], Z[lcs=='QA',1], n_levels=[.002,.003,.004], linewidths=.75, bw=2, color='k')\n",
    "sns.kdeplot(Z[poets,0], Z[poets,1], n_levels=[.0006,.001,.002], linewidths=.75, bw=2, color='k')\n",
    "\n",
    "Z = Z_hathi[1]\n",
    "plt.sca(ax[1])\n",
    "sns.kdeplot(Z[lcs=='QA',0], Z[lcs=='QA',1], n_levels=[.004, .008, .015], linewidths=.75, bw=2, color='k')\n",
    "sns.kdeplot(Z[poets,0], Z[poets,1], n_levels=[.001, .002, .005], linewidths=.75, bw=2, color='k')\n",
    "\n",
    "# labels\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.text(-3, 37, 'Poetry', fontsize=7)\n",
    "plt.text(40, -25, 'Math', fontsize=7)\n",
    "\n",
    "# colorbar\n",
    "plt.sca(ax[0])\n",
    "cbar = plt.colorbar(cax=cax)\n",
    "cbar.set_alpha(1)\n",
    "cbar.solids.set_edgecolor('face')\n",
    "cbar.solids.set_rasterized(True)\n",
    "cbar.draw_all()\n",
    "cbar.set_ticks([1700,1750,1800,1850,1900,1950,2000])\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig('figures/fig-hathi.pdf', dpi=600)\n",
    "\n",
    "hpos = [50, 20]\n",
    "hwidth = [10, 10]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.sca(ax[i])\n",
    "    ax[i].autoscale(False)\n",
    "    yl = plt.ylim()\n",
    "    vpos      = yl[0] + (yl[1]-yl[0]) * .15\n",
    "    vposlabel = yl[0] + (yl[1]-yl[0]) * .10\n",
    "    plt.plot([hpos[i], hpos[i]+hwidth[i]], [vpos,vpos], 'k', linewidth=1)\n",
    "    plt.text(hpos[i] + hwidth[i]/2, vposlabel, str(hwidth[i]), ha='center')\n",
    "    \n",
    "plt.text(0, 1.05, 'A', transform = plt.gcf().get_axes()[0].transAxes, fontsize=8, fontweight='bold')\n",
    "plt.text(0, 1.05, 'B', transform = plt.gcf().get_axes()[1].transAxes, fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.savefig('figures/fig-hathi.pdf', dpi=600)\n",
    "plt.savefig('figures/png/fig-hathi.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
